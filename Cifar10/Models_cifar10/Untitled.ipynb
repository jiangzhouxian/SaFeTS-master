{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "930f01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "from backbones.ResNet import ResNet18\n",
    "from backbones.VGG import VGG16\n",
    "from backbones.DenseNet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ecaae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 11173962\n",
      "Files already downloaded and verified\n",
      "0.9534\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "model = ResNet18().to(device)\n",
    "# 加载保存的模型checkpoint\n",
    "checkpoint_path = './checkpoint/ResNet18-CIFAR10.pth'  # 替换为实际路径\n",
    "params = list(model.parameters())\n",
    "num_params = sum(p.numel() for p in params)\n",
    "print(f'Number of parameters: {num_params}')\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 从checkpoint中提取模型的state_dict并加载到模型中\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='Dataset', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "test_acc = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    test_acc = correct / total\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fcc3c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 16865354\n",
      "Files already downloaded and verified\n",
      "0.9388\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "model = VGG16().to(device)\n",
    "# 加载保存的模型checkpoint\n",
    "checkpoint_path = './checkpoint/VGG16-CIFAR10.pth'  # 替换为实际路径\n",
    "params = list(model.parameters())\n",
    "num_params = sum(p.numel() for p in params)\n",
    "print(f'Number of parameters: {num_params}')\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# 从checkpoint中提取模型的state_dict并加载到模型中\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='Dataset', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "test_acc = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    test_acc = correct / total\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80f1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
